{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as metrics # accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('plot_confusion_matrix.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows in train set: 0\n",
      "Dropped rows in train set: 0\n"
     ]
    }
   ],
   "source": [
    "# loading train and test data and cleaning missing values\n",
    "raw_df_train = pd.read_csv('../pendigits_data/pendigits.tra', delimiter=',', header=None)\n",
    "raw_df_test = pd.read_csv('../pendigits_data/pendigits.tes', delimiter=',', header=None)\n",
    "# print(raw_df_train.head()) # prints sample of the dataset\n",
    "train_df_clean = raw_df_train.dropna() # drop any rows with missing values\n",
    "print(\"Dropped rows in train set: %d\" %(raw_df_train.shape[0] - train_df_clean.shape[0])) # number of rows dropped for some missing values\n",
    "# print(train_df_clean.describe()) # prints statistics column wise for train data\n",
    "\n",
    "test_df_clean = raw_df_test.dropna()\n",
    "print(\"Dropped rows in train set: %d\" %(raw_df_test.shape[0] - test_df_clean.shape[0])) # number of rows dropped for some missing values\n",
    "# print(test_df_clean.describe()) # prints statistics column wise for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7494, 16) (7494,) (3498, 16) (3498,)\n"
     ]
    }
   ],
   "source": [
    "# seperating the label column for train and test set\n",
    "x_train = train_df_clean.drop(axis=1, columns=[16])\n",
    "y_train = train_df_clean.iloc[:, 16]\n",
    "\n",
    "x_test = test_df_clean.drop(axis=1, columns=[16])\n",
    "y_test = test_df_clean.iloc[:, 16]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuray_precision_recall(y_true, y_predict):\n",
    "    \"\"\"Prints accuray, presion for each classes and recall for each classes.\"\"\"\n",
    "    print(metrics.accuracy_score(y_true, y_predict)) # accuracy score\n",
    "    print(metrics.precision_score(y_true, y_predict, average=None)) # precision scores for each class\n",
    "    print(metrics.recall_score(y_true, y_predict, average=None)) # recall score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# gini decision tree model. accracy, precision and recall for training instances. And confusion matrix.\n",
    "gini_model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "gini_model.fit(x_train, y_train)\n",
    "y_predict = gini_model.predict(x_train)\n",
    "print_accuray_precision_recall(y_train, y_predict)\n",
    "#plot_confusion_matrix(y_train, y_predict, classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210977701543739\n",
      "[0.95 0.86 0.88 0.88 0.98 0.95 0.95 0.91 0.92 0.93]\n",
      "[0.96 0.88 0.96 0.93 0.96 0.85 0.95 0.9  0.9  0.93]\n"
     ]
    }
   ],
   "source": [
    "# gini decision tree model. accracy, precision and recall for test instances. And confusion matrix.\n",
    "gini_model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "gini_model.fit(x_train, y_train)\n",
    "y_predict = gini_model.predict(x_test)\n",
    "print_accuray_precision_recall(y_test, y_predict)\n",
    "#plot_confusion_matrix(y_test, y_predict, classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.97, 0.95, 0.96, 0.97])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gini decision tree model, with 5-fold cross validation\n",
    "gini_model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "cross_val_score(gini_model, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# entropy decision tree model. accracy, precision and recall for train instances. And confusion matrix.\n",
    "entropy_model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "entropy_model.fit(x_train, y_train)\n",
    "y_predict = entropy_model.predict(x_train)\n",
    "print_accuray_precision_recall(y_train, y_predict)\n",
    "#plot_confusion_matrix(y_train, y_predict, classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210977701543739\n",
      "[0.98 0.87 0.88 0.87 0.95 0.94 0.96 0.97 0.91 0.9 ]\n",
      "[0.97 0.9  0.96 0.94 0.92 0.83 0.9  0.9  0.98 0.91]\n"
     ]
    }
   ],
   "source": [
    "# entropy decision tree model. accracy, precision and recall for test instances. And confusion matrix.\n",
    "entropy_model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "entropy_model.fit(x_train, y_train)\n",
    "y_predict = entropy_model.predict(x_test)\n",
    "print_accuray_precision_recall(y_test, y_predict)\n",
    "#plot_confusion_matrix(y_test, y_predict, classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.97, 0.97, 0.97, 0.97])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy decision tree model, with 5-fold cross validation\n",
    "entropy_model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "cross_val_score(entropy_model, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
